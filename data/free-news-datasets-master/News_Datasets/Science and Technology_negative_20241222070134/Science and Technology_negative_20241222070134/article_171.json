{
    "thread": {
        "uuid": "86cf2ba735cdd7226b52cbcc4d6944dfad2df398",
        "url": "https://www.govtech.com/security/health-device-data-is-protected-but-also-used-shared",
        "site_full": "www.govtech.com",
        "site": "govtech.com",
        "site_section": "https://govtech.com",
        "site_categories": [
            "media"
        ],
        "section_title": "Government Technology State &amp; Local Articles - e.Republic",
        "title": "Health Device Data Is Protected, but Also Used, Shared",
        "title_full": "Health Device Data Is Protected, but Also Used, Shared",
        "published": "2024-11-22T00:47:00.000+02:00",
        "replies_count": 0,
        "participants_count": 0,
        "site_type": "news",
        "country": "US",
        "main_image": "https://erepublic.brightspotcdn.com/dims4/default/a08aa75/2147483647/strip/true/crop/5111x2485+0+322/resize/1440x700!/quality/90/?url=http%3A%2F%2Ferepublic-brightspot.s3.us-west-2.amazonaws.com%2F24%2F49%2F9f0b4eb5472396706efb02680861%2Fadobestock-991286520.jpeg",
        "performance_score": 0,
        "domain_rank": 4116,
        "domain_rank_updated": "2024-11-18T23:00:00.000+02:00",
        "social": {
            "facebook": {
                "likes": 0,
                "comments": 0,
                "shares": 0
            },
            "vk": {
                "shares": 0
            }
        }
    },
    "uuid": "86cf2ba735cdd7226b52cbcc4d6944dfad2df398",
    "url": "https://www.govtech.com/security/health-device-data-is-protected-but-also-used-shared",
    "ord_in_thread": 0,
    "parent_url": null,
    "author": null,
    "published": "2024-11-22T00:47:00.000+02:00",
    "title": "Health Device Data Is Protected, but Also Used, Shared",
    "text": "Health Device Data Is Protected, but Also Used, Shared\nInformation collected by wearable technology, from smartwatches to fitness trackers and smart rings, is safeguarded by laws in some states. But much of it falls outside the federal Health Insurance Portability and Accountability Act, and can be sold or provided to third parties.\n(TNS) — Every day millions of people share more intimate information with their accessories than they do with their spouse.\nWearable technology — smartwatches, smart rings, fitness trackers and the like — monitors body-centric data such as your heart rate, steps taken and calories burned, and may record where you go along the way. Like Santa Claus, it knows when you are sleeping (and how well), it knows when you're awake, it knows when you've been idle or exercising, and it keeps track of all of it.\nPeople are also sharing sensitive health information on\nThese devices and services have excited consumers hoping for better insight into their health and lifestyle choices. But the lack of oversight into how body-centric data are used and shared with third parties has prompted concerns from privacy experts, who warn that the data could be sold or lost through data breaches, then used to raise insurance premiums, discriminate surreptitiously against applicants for jobs or housing, and even perform surveillance.\nThe use of wearable technology and medical apps surged in the years following the COVID-19 pandemic, but\n\"I've been studying the intersections of emerging technologies, data-driven technologies, AI and human rights and social justice for the past 15 years, and since the pandemic I've noticed the industry has become hyper-focused on our bodies,\" said Mozilla Foundation technology fellow Júlia Keserű, who conducted the research. \"That permeates into all kinds of areas of our lives and all kinds of domains within the tech industry.\"\nThe report \"From Skin to Screen: Bodily Integrity in the Digital Age\" recommends that existing data protection laws be clarified to encompass all forms of bodily data. It also calls for expanding national health privacy laws to cover health-related information collected from health apps and fitness trackers and making it easier for users to opt out of body-centric data collections.\nResearchers have been raising alarms about health data privacy for years. Data collected by companies are often sold to data brokers or groups that buy, sell and trade data from the Internet to create detailed consumer profiles.\nBody-centric data can include information such as the fingerprints used to unlock phones, face scans from facial recognition technology, and data from fitness and fertility trackers, mental health apps and digital medical records.\nOne of the key reasons health information has value to companies — even when the person's name is not associated with it — is that advertisers can use the data to send targeted ads to groups of people based on certain details they share. The information contained in these consumer profiles is becoming so detailed, however, that when paired with other data sets that include location information, it could be possible to target specific individuals, Keserű said.\nLocation data can \"expose sophisticated insights about people's health status, through their visits to places like hospitals or abortions clinics,\" Mozilla's report said, adding that \"companies like Google have been reported to keep such data even after promising to delete it.\"\nIn two public surveys conducted as part of the research, Keserű said, participants were outraged and felt exploited in scenarios where their health data were sold for a profit without their knowledge.\n\"We need a new approach to our digital interactions that recognizes the fundamental rights of individuals to safeguard their bodily data, an issue that speaks directly to human autonomy and dignity,\" Keserű said. \"As technology continues to advance, it is critical that our laws and practices evolve to meet the unique challenges of this era.\"\nConsumers often take part in these technologies without fully understanding the implications.\nLast month,\nWhile X's privacy policy says that the company will not sell user data to third parties, it does share some information with certain business partners.\nGaps in existing laws have allowed the widespread sharing of biometric and other body-related data.\nHealth information provided to hospitals, doctor's offices and medical insurance companies is protected from disclosure under the\n\"In the U.S. because we don't have a comprehensive federal privacy law ... it falls to the state level,\" she said. But not every state has weighed in on the issue.\nWashington, Nevada and Connecticut all recently passed laws to provide safeguards for consumer health data.\nIn California, the California Privacy Rights Act regulates how businesses can use certain types of sensitive information, including biometric information, and requires them to offer consumers the ability to opt out of disclosure of sensitive personal information.\n\"This information being sold or shared with data brokers and other entities hypercharge the online profiling that we're so used to at this point, and the more sensitive the data, the more sophisticated the profiling can be,\" Bernstein said. \"A lot of the sharing or selling with third parties is outside the scope of what a consumer would reasonably expect.\"\nHealth information has become a prime target for hackers seeking to extort healthcare agencies and individuals after accessing sensitive patient data.\nHealth-related cybersecurity breaches and ransom attacks increased more than 4,000% between 2009 and 2023, targeting the booming market of body-centric data, which is expected to exceed $500 billion by 2030, according to the report.\n\"Nonconsensual data sharing is a big issue,\" Keserű said. \"Even if it's biometric data or health data, a lot of the companies are just sharing that data without you knowing, and that is causing a lot of anxiety and questions.\"\n©2024 Los Angeles Times, Distributed by\nWearable technology — smartwatches, smart rings, fitness trackers and the like — monitors body-centric data such as your heart rate, steps taken and calories burned, and may record where you go along the way. Like Santa Claus, it knows when you are sleeping (and how well), it knows when you're awake, it knows when you've been idle or exercising, and it keeps track of all of it.\nPeople are also sharing sensitive health information on\n[health and wellness apps](https://www.latimes.com/business/technology/story/2023-05-02/mental-health-apps-privacy-risk-what-to-look-for), including online mental health and counseling programs. Some women use period tracker apps to map out their monthly cycle.These devices and services have excited consumers hoping for better insight into their health and lifestyle choices. But the lack of oversight into how body-centric data are used and shared with third parties has prompted concerns from privacy experts, who warn that the data could be sold or lost through data breaches, then used to raise insurance premiums, discriminate surreptitiously against applicants for jobs or housing, and even perform surveillance.\nThe use of wearable technology and medical apps surged in the years following the COVID-19 pandemic, but\n[research released by Mozilla on Wednesday](https://www.databodyfutures.org/databodyintegrity)indicates that current laws offer little protection for consumers who are often unaware just how much of their health data are being collected and shared by companies.\"I've been studying the intersections of emerging technologies, data-driven technologies, AI and human rights and social justice for the past 15 years, and since the pandemic I've noticed the industry has become hyper-focused on our bodies,\" said Mozilla Foundation technology fellow Júlia Keserű, who conducted the research. \"That permeates into all kinds of areas of our lives and all kinds of domains within the tech industry.\"\nThe report \"From Skin to Screen: Bodily Integrity in the Digital Age\" recommends that existing data protection laws be clarified to encompass all forms of bodily data. It also calls for expanding national health privacy laws to cover health-related information collected from health apps and fitness trackers and making it easier for users to opt out of body-centric data collections.\nResearchers have been raising alarms about health data privacy for years. Data collected by companies are often sold to data brokers or groups that buy, sell and trade data from the Internet to create detailed consumer profiles.\nBody-centric data can include information such as the fingerprints used to unlock phones, face scans from facial recognition technology, and data from fitness and fertility trackers, mental health apps and digital medical records.\nOne of the key reasons health information has value to companies — even when the person's name is not associated with it — is that advertisers can use the data to send targeted ads to groups of people based on certain details they share. The information contained in these consumer profiles is becoming so detailed, however, that when paired with other data sets that include location information, it could be possible to target specific individuals, Keserű said.\nLocation data can \"expose sophisticated insights about people's health status, through their visits to places like hospitals or abortions clinics,\" Mozilla's report said, adding that \"companies like Google have been reported to keep such data even after promising to delete it.\"\n[A 2023 report by Duke University](https://techpolicy.sanford.duke.edu/data-brokers-and-the-sale-of-americans-mental-health-data/#:~:text=Key%20Findings%3A&text=26%20of%20the%2037%20contacted,the%20requested%20mental%20health%20data.)revealed that data brokers were selling sensitive data on individuals' mental health conditions on the open market. While many brokers deleted personal identifiers, some provided names and addresses of individuals seeking mental health assistance, according to the report.In two public surveys conducted as part of the research, Keserű said, participants were outraged and felt exploited in scenarios where their health data were sold for a profit without their knowledge.\n\"We need a new approach to our digital interactions that recognizes the fundamental rights of individuals to safeguard their bodily data, an issue that speaks directly to human autonomy and dignity,\" Keserű said. \"As technology continues to advance, it is critical that our laws and practices evolve to meet the unique challenges of this era.\"\nConsumers often take part in these technologies without fully understanding the implications.\nLast month,\n[Elon Musk suggested on X](https://x.com/elonmusk/status/1851206080564773344?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1851206080564773344%7Ctwgr%5E9b8cad1e9b0b149f21684eed4e76cc9e3927fd36%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fwww.foxnews.com%2Fhealth%2Felon-musk-wants-people-submit-medical-scans-grok-ai-chatbot)that users submit X-rays, PET scans, MRIs and other medical images to Grok, the platform's artificial intelligence chatbot, to seek diagnoses. The issue alarmed privacy experts, but many X users heeded Musk's call and submitted health information to the chatbot.While X's privacy policy says that the company will not sell user data to third parties, it does share some information with certain business partners.\nGaps in existing laws have allowed the widespread sharing of biometric and other body-related data.\nHealth information provided to hospitals, doctor's offices and medical insurance companies is protected from disclosure under the\n[Health Insurance Portability and Accountability Act](https://www.cdc.gov/phlp/php/resources/health-insurance-portability-and-accountability-act-of-1996-hipaa.html?CDC_AAref_Val=https://www.cdc.gov/phlp/publications/topic/hipaa.html), known as HIPAA, which established federal standards protecting such information from release without the patient's consent. But health data collected by many wearable devices and health and wellness apps don't fall under HIPAA's umbrella, said Suzanne Bernstein, counsel at Electronic Privacy Information Center.\"In the U.S. because we don't have a comprehensive federal privacy law ... it falls to the state level,\" she said. But not every state has weighed in on the issue.\nWashington, Nevada and Connecticut all recently passed laws to provide safeguards for consumer health data.\n[Washington, D.C., in July introduced legislation](https://oag.dc.gov/release/attorney-general-schwalb-introduces-privacy-legislation)that aimed to require tech companies to adhere to strengthened privacy provisions regarding the collection, sharing, use or sale of consumer health data.In California, the California Privacy Rights Act regulates how businesses can use certain types of sensitive information, including biometric information, and requires them to offer consumers the ability to opt out of disclosure of sensitive personal information.\n\"This information being sold or shared with data brokers and other entities hypercharge the online profiling that we're so used to at this point, and the more sensitive the data, the more sophisticated the profiling can be,\" Bernstein said. \"A lot of the sharing or selling with third parties is outside the scope of what a consumer would reasonably expect.\"\nHealth information has become a prime target for hackers seeking to extort healthcare agencies and individuals after accessing sensitive patient data.\nHealth-related cybersecurity breaches and ransom attacks increased more than 4,000% between 2009 and 2023, targeting the booming market of body-centric data, which is expected to exceed $500 billion by 2030, according to the report.\n\"Nonconsensual data sharing is a big issue,\" Keserű said. \"Even if it's biometric data or health data, a lot of the companies are just sharing that data without you knowing, and that is causing a lot of anxiety and questions.\"\n©2024 Los Angeles Times, Distributed by",
    "highlightText": "",
    "highlightTitle": "",
    "highlightThreadTitle": "",
    "language": "english",
    "sentiment": "negative",
    "categories": [
        "Health",
        "Science and Technology"
    ],
    "ai_allow": true,
    "canonical": false,
    "webz_reporter": false,
    "external_links": [
        "https://www.latimes.com/business/technology/story/2023-05-02/mental-health-apps-privacy-risk-what-to-look-for",
        "https://techpolicy.sanford.duke.edu/data-brokers-and-the-sale-of-americans-mental-health-data/#:~:text=Key%20Findings%3A&text=26%20of%20the%2037%20contacted,the%20requested%20mental%20health%20data.",
        "https://x.com/elonmusk/status/1851206080564773344?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1851206080564773344%7Ctwgr%5E9b8cad1e9b0b149f21684eed4e76cc9e3927fd36%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fwww.foxnews.com%2Fhealth%2Felon-musk-wants-people-submit-medical-scans-grok-ai-chatbot",
        "https://oag.dc.gov/release/attorney-general-schwalb-introduces-privacy-legislation",
        "https://www.databodyfutures.org/databodyintegrity",
        "https://www.cdc.gov/phlp/php/resources/health-insurance-portability-and-accountability-act-of-1996-hipaa.html?CDC_AAref_Val=https://www.cdc.gov/phlp/publications/topic/hipaa.html",
        "https://cdc.gov/phlp/php/resources/health-insurance-portability-and-accountability-act-of-1996-hipaa.html?CDC_AAref_Val=https://cdc.gov/phlp/publications/topic/hipaa.html",
        "https://www.oag.dc.gov/release/attorney-general-schwalb-introduces-privacy-legislation",
        "https://x.com/elonmusk/status/1851206080564773344",
        "https://latimes.com/business/technology/story/2023-05-02/mental-health-apps-privacy-risk-what-to-look-for",
        "https://www.x.com/elonmusk/status/1851206080564773344?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1851206080564773344%7Ctwgr%5E9b8cad1e9b0b149f21684eed4e76cc9e3927fd36%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fwww.foxnews.com%2Fhealth%2Felon-musk-wants-people-submit-medical-scans-grok-ai-chatbot",
        "https://www.techpolicy.sanford.duke.edu/data-brokers-and-the-sale-of-americans-mental-health-data/#:~:text=Key%20Findings%3A&text=26%20of%20the%2037%20contacted,the%20requested%20mental%20health%20data.",
        "https://www.cdc.gov/phlp/php/resources/health-insurance-portability-and-accountability-act-of-1996-hipaa.html",
        "https://databodyfutures.org/databodyintegrity"
    ],
    "external_images": [],
    "entities": {
        "persons": [],
        "organizations": [],
        "locations": []
    },
    "syndication": {
        "syndicated": false,
        "syndicate_id": "86cf2ba735cdd7226b52cbcc4d6944dfad2df398",
        "first_syndicated": true
    },
    "rating": null,
    "crawled": "2024-11-22T03:24:47.108+02:00",
    "updated": "2024-11-22T03:24:47.108+02:00"
}