{
    "thread": {
        "uuid": "44fad7ad8ef82da673e4459fd8174aa5a02eb197",
        "url": "https://www.homelandsecuritynewswire.com/dr20240822-artificial-intelligence-at-war",
        "site_full": "www.homelandsecuritynewswire.com",
        "site": "homelandsecuritynewswire.com",
        "site_section": "http://www.homelandsecuritynewswire.com/rss.xml",
        "site_categories": [
            "media",
            "hacking",
            "tech",
            "law_government_and_politics",
            "politics"
        ],
        "section_title": "Homeland Security Newswire",
        "title": "AI, cybersecurity, killer robot, existential threats",
        "title_full": "AI, cybersecurity, killer robot, existential threats | Homeland Security Newswire",
        "published": "2024-08-22T03:00:00.000+03:00",
        "replies_count": 0,
        "participants_count": 1,
        "site_type": "news",
        "country": "US",
        "main_image": "",
        "performance_score": 0,
        "domain_rank": 71404,
        "domain_rank_updated": "2024-08-20T13:10:26.000+03:00",
        "reach": null,
        "social": {
            "facebook": {
                "likes": 0,
                "comments": 0,
                "shares": 0
            },
            "vk": {
                "shares": 0
            }
        }
    },
    "uuid": "44fad7ad8ef82da673e4459fd8174aa5a02eb197",
    "url": "https://www.homelandsecuritynewswire.com/dr20240822-artificial-intelligence-at-war",
    "ord_in_thread": 0,
    "parent_url": null,
    "author": "Peter Layton",
    "published": "2024-08-22T03:00:00.000+03:00",
    "title": "AI, cybersecurity, killer robot, existential threats",
    "text": "AIArtificial Intelligence at War The Gaza war has shown that the use of AI in tactical targeting can drive military strategy by encouraging decision-making bias. At the start of the conflict, an Israeli Defense Force AI system called Lavender apparently identified 37,000 people linked to Hamas. Its function quickly shifted from gathering long-term intelligence to rapidly identifying individual operatives to target. There’s a [global arms race](https://link.springer.com/book/10.1007/978-3-031-58649-1) under way to work out how best to use artificial intelligence for military purposes. The Gaza and Ukraine wars are now accelerating this. These conflicts might inform Australia and others in the region as they prepare for a possible AI-fueled ‘ [hyperwar](https://www.usni.org/magazines/proceedings/2017/july/hyperwar)’ closer to home, given that China envisages fighting wars using [automated decision-making](https://warontherocks.com/2021/10/schrodingers-military-challenges-for-the-chinas-military-modernization-ambitions/) under the rubric of what it calls ‘ [intelligentization](https://www.defenseone.com/ideas/2021/09/how-chinese-strategists-think-ai-will-power-military-leap-ahead/185409/)’. The Gaza war has shown that the use of AI in tactical targeting can drive military strategy by encouraging decision-making bias. At the start of the conflict, an Israeli Defense Force AI system called Lavender apparently [identified](https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes) 37,000 people linked to Hamas. Its function quickly shifted from gathering long-term intelligence to rapidly identifying individual operatives to target. Foot soldiers were easier to [swiftly locate and attack](https://www.972mag.com/lavender-ai-israeli-army-gaza/) than senior commanders, so they dominated the attack schedule. Lavender created a simplified digital model of the battlefield, allowing dramatically faster targeting and much higher rates of attacks than in earlier conflicts. Human analysts did review Lavender’s recommendations before authorizing attacks, but they quickly grew to trust it, considering it [more reliable](https://foreignpolicy.com/2024/05/02/israel-military-artificial-intelligence-targeting-hamas-gaza-deaths-lavender/). Humans often spent only 20 seconds considering Lavender’s target recommendations before approving them. These human analysts displayed [automation bias](https://www.forbes.com/sites/brycehoffman/2024/03/10/automation-bias-what-it-is-and-how-to-overcome-it/) and [action bias](https://thedecisionlab.com/biases/action-bias). Indeed, it could be said that Lavender was encouraging and amplifying these biases. In a way, the humans offloaded their thinking to the machine. Human-machine teams are considered by many, including the [Australian Defense Force](https://tasdcrc.com.au/wp-content/uploads/2020/12/ADF-Concept-Robotics.pdf), to be central to future warfighting. The way Lavender’s tactical targeting drove military strategy suggests that the AI machine part should be designed to work with humans on the task they are undertaking, not be treated as a part able to be quickly switched between different functions. Otherwise, humans might lose sight of the strategic or operational context and instead focus on the machine-generated answers. For example, the purpose-designed [Ukrainian GIS Arta system](https://asiatimes.com/2022/07/musks-tech-put-to-deadly-weapon-effect-in-ukraine/) takes a bottom-up approach to target selection by giving people a well-fused picture of the battlespace, not a recommendation derived opaquely of what to attack. It’s described as ‘ [Uber for artillery](https://www.newamerica.org/future-frontlines/blogs/how-ukraines-uber-for-artillery-is-leading-the-software-war-against-russia/)’. Human users apply the context as they understand it to decide what is to be targeted.",
    "highlightText": "",
    "highlightTitle": "",
    "highlightThreadTitle": "",
    "language": "english",
    "sentiment": "negative",
    "categories": [
        "Science and Technology",
        "War, Conflict and Unrest",
        "Social Issue"
    ],
    "ai_allow": false,
    "webz_reporter": false,
    "external_links": [
        "https://defenseone.com/ideas/2021/09/how-chinese-strategists-think-ai-will-power-military-leap-ahead/185409/)’.",
        "https://www.thedecisionlab.com/biases/action-bias).",
        "https://link.springer.com/book/10.1007/978-3-031-58649-1)",
        "https://www.link.springer.com/book/10.1007/978-3-031-58649-1)",
        "https://www.asiatimes.com/2022/07/musks-tech-put-to-deadly-weapon-effect-in-ukraine/)",
        "https://972mag.com/lavender-ai-israeli-army-gaza/)",
        "https://www.forbes.com/sites/brycehoffman/2024/03/10/automation-bias-what-it-is-and-how-to-overcome-it/)",
        "https://usni.org/magazines/proceedings/2017/july/hyperwar)’",
        "https://asiatimes.com/2022/07/musks-tech-put-to-deadly-weapon-effect-in-ukraine/)",
        "https://www.newamerica.org/future-frontlines/blogs/how-ukraines-uber-for-artillery-is-leading-the-software-war-against-russia/)’.",
        "https://www.warontherocks.com/2021/10/schrodingers-military-challenges-for-the-chinas-military-modernization-ambitions/)",
        "https://forbes.com/sites/brycehoffman/2024/03/10/automation-bias-what-it-is-and-how-to-overcome-it/)",
        "https://www.foreignpolicy.com/2024/05/02/israel-military-artificial-intelligence-targeting-hamas-gaza-deaths-lavender/).",
        "https://newamerica.org/future-frontlines/blogs/how-ukraines-uber-for-artillery-is-leading-the-software-war-against-russia/)’.",
        "https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes)",
        "https://www.defenseone.com/ideas/2021/09/how-chinese-strategists-think-ai-will-power-military-leap-ahead/185409/)’.",
        "https://tasdcrc.com.au/wp-content/uploads/2020/12/ADF-Concept-Robotics.pdf),",
        "https://warontherocks.com/2021/10/schrodingers-military-challenges-for-the-chinas-military-modernization-ambitions/)",
        "https://www.tasdcrc.com.au/wp-content/uploads/2020/12/ADF-Concept-Robotics.pdf),",
        "https://thedecisionlab.com/biases/action-bias).",
        "https://www.usni.org/magazines/proceedings/2017/july/hyperwar)’",
        "https://theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes)",
        "https://foreignpolicy.com/2024/05/02/israel-military-artificial-intelligence-targeting-hamas-gaza-deaths-lavender/).",
        "https://www.972mag.com/lavender-ai-israeli-army-gaza/)"
    ],
    "external_images": [],
    "entities": {
        "persons": [],
        "organizations": [
            {
                "name": "hamas",
                "sentiment": "none"
            }
        ],
        "locations": [
            {
                "name": "gaza",
                "sentiment": "none"
            },
            {
                "name": "china",
                "sentiment": "none"
            },
            {
                "name": "ukraine",
                "sentiment": "none"
            },
            {
                "name": "australia",
                "sentiment": "none"
            }
        ]
    },
    "syndication": null,
    "rating": null,
    "crawled": "2024-08-23T02:27:06.648+03:00",
    "updated": "2024-08-23T02:27:06.648+03:00"
}