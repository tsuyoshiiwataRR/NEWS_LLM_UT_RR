{
    "thread": {
        "uuid": "436bf37f230f89bc28e928075bcdb46d046d66f9",
        "url": "https://en.shafaqna.com/393112/stat-news-chatbots-fail-to-address-mental-health-risks",
        "site_full": "en.shafaqna.com",
        "site": "shafaqna.com",
        "site_section": "https://www.en.shafaqna.com",
        "site_categories": [
            "religion",
            "islam",
            "top_news_iq",
            "top_news"
        ],
        "section_title": "International Shia News Agency &#8211; Shafaqna English | Latest news and breaking stories on Shia Islam",
        "title": "Stat News: Chatbots Fail to Address Mental Health Risks",
        "title_full": "Stat News: Chatbots Fail to Address Mental Health Risks",
        "published": "2024-12-20T00:18:00.000+02:00",
        "replies_count": 0,
        "participants_count": 1,
        "site_type": "news",
        "country": "US",
        "main_image": "",
        "performance_score": 0,
        "domain_rank": 29968,
        "domain_rank_updated": "2024-12-16T23:00:00.000+02:00",
        "social": {
            "facebook": {
                "likes": 0,
                "comments": 0,
                "shares": 0
            },
            "vk": {
                "shares": 0
            }
        }
    },
    "uuid": "436bf37f230f89bc28e928075bcdb46d046d66f9",
    "url": "https://en.shafaqna.com/393112/stat-news-chatbots-fail-to-address-mental-health-risks",
    "ord_in_thread": 0,
    "parent_url": null,
    "author": "parniani",
    "published": "2024-12-20T00:18:00.000+02:00",
    "title": "Stat News: Chatbots Fail to Address Mental Health Risks",
    "text": "Shafaqna English- Recent research highlights significant risks in AI chatbots failing to address mental health crises or dangerous intent. Studies tested multiple models with prompts mimicking psychiatric emergencies, revealing that most failed to detect symptoms of mania, psychosis, or suicidal thoughts, often providing unsafe or harmful responses. This raises ethical concerns as chatbots become integrated into mental health support systems, as Stat News reported.\nExperts warn that without proper safeguards, these tools could inadvertently escalate harm or assist in planning violent acts. AI-driven personalized interactions might reveal more about usersâ€™ mental states but also introduce vulnerabilities.\nThe study underscores the need for rigorous safety training and ethical oversight in AI development, particularly for tools used in mental health contexts. It suggests combining fine-tuning for mental health with enhanced safety protocols to mitigate risks, ensuring chatbots support users effectively while preventing potential misuse. These findings call for urgent industry-wide efforts to address gaps in chatbot safety and reliability.\nSource: Stat News\nwww.shafaqna.com",
    "highlightText": "",
    "highlightTitle": "",
    "highlightThreadTitle": "",
    "language": "english",
    "sentiment": "negative",
    "categories": [
        "Health"
    ],
    "topics": [
        "Health->mental health and disorder",
        "Health->medical service",
        "Health->health care approach"
    ],
    "ai_allow": true,
    "has_canonical": false,
    "webz_reporter": false,
    "external_links": [
        "https://www.statnews.com/2024/12/19/ai-chatbot-research-mental-health-bots-fail-to-spot-mania-psychosis-risk-of-violence/",
        "https://www.statnews.com/2024/12/19/ai-chatbot-research-mental-health-bots-fail-to-spot-mania-psychosis-risk-of-violence",
        "https://statnews.com/2024/12/19/ai-chatbot-research-mental-health-bots-fail-to-spot-mania-psychosis-risk-of-violence/"
    ],
    "external_images": [],
    "entities": {
        "persons": [],
        "organizations": [],
        "locations": []
    },
    "syndication": {
        "syndicated": false,
        "syndicate_id": null,
        "first_syndicated": false
    },
    "rating": null,
    "crawled": "2024-12-20T00:50:52.248+02:00",
    "updated": "2024-12-20T00:50:52.248+02:00"
}